name: End-to-End Pipeline CI/CD

on:
  push:
    branches: [ demo-4 ]
    paths:
      - 'demo-4/**'
  pull_request:
    branches: [ demo-4 ]
    paths:
      - 'demo-4/**'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: true
        default: 'staging'
        type: choice
        options:
          - development
          - staging
          - production
      pipeline_stages:
        description: 'Pipeline stages to run'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - data-prep
          - preprocessing
          - training
          - evaluation
          - deployment
      force_run:
        description: 'Force pipeline execution'
        required: false
        default: false
        type: boolean

env:
  MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI || 'file:./mlruns' }}
  MLFLOW_EXPERIMENT_NAME: end_to_end_pipeline_cicd
  PYTHON_VERSION: '3.11'

jobs:
  setup-and-validate:
    name: Setup and Pipeline Validation
    runs-on: ubuntu-latest
    outputs:
      environment: ${{ steps.set-env.outputs.environment }}
      should-run-pipeline: ${{ steps.check-pipeline.outputs.should-run }}
      pipeline-stages: ${{ steps.set-stages.outputs.stages }}
      pipeline-id: ${{ steps.set-pipeline-id.outputs.pipeline-id }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Cache Python dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      timeout-minutes: 10
      run: |
        cd demo-4
        pip install --upgrade pip
        pip install -r requirements.txt --timeout 300
        
    - name: Determine environment
      id: set-env
      run: |
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          echo "environment=${{ github.event.inputs.environment }}" >> $GITHUB_OUTPUT
        elif [ "${{ github.ref }}" = "refs/heads/main" ]; then
          echo "environment=production" >> $GITHUB_OUTPUT
        elif [ "${{ github.ref }}" = "refs/heads/staging" ]; then
          echo "environment=staging" >> $GITHUB_OUTPUT
        else
          echo "environment=development" >> $GITHUB_OUTPUT
        fi
        
    - name: Set pipeline stages
      id: set-stages
      run: |
        if [ "${{ github.event.inputs.pipeline_stages }}" = "all" ] || [ -z "${{ github.event.inputs.pipeline_stages }}" ]; then
          echo "stages=[\"data-preparation\", \"preprocessing\", \"training\", \"evaluation\", \"deployment\"]" >> $GITHUB_OUTPUT
        else
          echo "stages=[\"${{ github.event.inputs.pipeline_stages }}\"]" >> $GITHUB_OUTPUT
        fi
        
    - name: Generate pipeline ID
      id: set-pipeline-id
      run: |
        PIPELINE_ID="pipeline_$(date +%Y%m%d_%H%M%S)_${{ github.sha }}"
        echo "pipeline-id=$PIPELINE_ID" >> $GITHUB_OUTPUT
        echo "🆔 Pipeline ID: $PIPELINE_ID"
        
    - name: Check if pipeline should run
      id: check-pipeline
      run: |
        if [ "${{ github.event.inputs.force_run }}" = "true" ]; then
          echo "should-run=true" >> $GITHUB_OUTPUT
          echo "Pipeline forced by user input"
        elif [ "${{ github.event_name }}" = "pull_request" ] || [ "${{ github.event_name }}" = "push" ]; then
          echo "should-run=true" >> $GITHUB_OUTPUT
          echo "Pipeline needed due to code changes"
        elif [ "${{ github.ref }}" = "refs/heads/main" ]; then
          echo "should-run=true" >> $GITHUB_OUTPUT
          echo "Pipeline needed for production deployment"
        else
          echo "should-run=false" >> $GITHUB_OUTPUT
          echo "No pipeline execution needed"
        fi
        
    - name: Validate MLflow connection
      timeout-minutes: 2
      run: |
        cd demo-4
        python -c "
        import mlflow
        import os
        import tempfile
        
        # Set up local tracking for CI/CD
        tracking_uri = os.getenv('MLFLOW_TRACKING_URI', 'file:///tmp/mlflow_cicd')
        mlflow.set_tracking_uri(tracking_uri)
        print(f'MLflow Tracking URI: {mlflow.get_tracking_uri()}')
        
        # Simple validation - just check if we can import and set experiment
        try:
            mlflow.set_experiment('cicd_validation_test')
            print('✅ MLflow validation successful')
        except Exception as e:
            print(f'⚠️ MLflow validation failed: {e}')
            print('Continuing with pipeline...')
        "
        
    - name: Pipeline configuration summary
      run: |
        echo "🔧 **Pipeline Configuration**" >> $GITHUB_STEP_SUMMARY
        echo "- **Environment**: ${{ steps.set-env.outputs.environment }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Pipeline execution needed**: ${{ steps.check-pipeline.outputs.should-run }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Pipeline stages**: ${{ steps.set-stages.outputs.stages }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Pipeline ID**: ${{ steps.set-pipeline-id.outputs.pipeline-id }}" >> $GITHUB_STEP_SUMMARY

  run-end-to-end-pipeline:
    name: Execute End-to-End ML Pipeline
    runs-on: ubuntu-latest
    needs: setup-and-validate
    if: needs.setup-and-validate.outputs.should-run-pipeline == 'true'
    environment: ${{ needs.setup-and-validate.outputs.environment }}
    outputs:
      pipeline-status: ${{ steps.pipeline-execution.outputs.status }}
      best-model-accuracy: ${{ steps.pipeline-execution.outputs.best-accuracy }}
      deployment-ready: ${{ steps.pipeline-execution.outputs.deployment-ready }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Cache Python dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('demo-4/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      timeout-minutes: 10
      run: |
        cd demo-4
        pip install --upgrade pip
        pip install -r requirements.txt --timeout 300
        
    - name: Set environment-specific parameters
      run: |
        ENV="${{ needs.setup-and-validate.outputs.environment }}"
        PIPELINE_ID="${{ needs.setup-and-validate.outputs.pipeline-id }}"
        
        echo "PIPELINE_ID=$PIPELINE_ID" >> $GITHUB_ENV
        echo "MLFLOW_EXPERIMENT_NAME=end_to_end_pipeline_${ENV}" >> $GITHUB_ENV
        
        # Environment-specific data generation parameters for loan approval dataset
        if [ "$ENV" = "development" ]; then
          echo "N_SAMPLES=1000" >> $GITHUB_ENV
        elif [ "$ENV" = "staging" ]; then
          echo "N_SAMPLES=2000" >> $GITHUB_ENV
        else  # production
          echo "N_SAMPLES=5000" >> $GITHUB_ENV
        fi
        
        # Model selection criteria
        if [ "$ENV" = "production" ]; then
          echo "MIN_ACCURACY_THRESHOLD=0.95" >> $GITHUB_ENV
          echo "ENABLE_HYPERPARAMETER_TUNING=true" >> $GITHUB_ENV
        elif [ "$ENV" = "staging" ]; then
          echo "MIN_ACCURACY_THRESHOLD=0.90" >> $GITHUB_ENV
          echo "ENABLE_HYPERPARAMETER_TUNING=true" >> $GITHUB_ENV
        else
          echo "MIN_ACCURACY_THRESHOLD=0.65" >> $GITHUB_ENV
          echo "ENABLE_HYPERPARAMETER_TUNING=false" >> $GITHUB_ENV
        fi
        
    - name: Execute end-to-end pipeline
      id: pipeline-execution
      timeout-minutes: 30
      run: |
        cd demo-4
        
        # Set environment variables for the pipeline
        export ENVIRONMENT="${{ needs.setup-and-validate.outputs.environment }}"
        export PIPELINE_ID="${{ env.PIPELINE_ID }}"
        
        # Run the pipeline using helper script
        python ../pipeline-helpers/cicd_pipeline_runner.py
        
    - name: Upload pipeline artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: pipeline-artifacts-${{ needs.setup-and-validate.outputs.environment }}
        path: |
          demo-4/pipeline_artifacts/
          demo-4/cicd_pipeline_summary.json
        retention-days: 30
        
    - name: Upload pipeline logs
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: pipeline-logs-${{ needs.setup-and-validate.outputs.environment }}
        path: |
          demo-4/*.log
        retention-days: 7

  validate-pipeline-output:
    name: Validate Pipeline Output
    runs-on: ubuntu-latest
    needs: [setup-and-validate, run-end-to-end-pipeline]
    if: needs.run-end-to-end-pipeline.result == 'success'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install dependencies
      timeout-minutes: 10
      run: |
        cd demo-4
        pip install --upgrade pip
        pip install -r requirements.txt --timeout 300
        
    - name: Download pipeline artifacts
      uses: actions/download-artifact@v4
      with:
        name: pipeline-artifacts-${{ needs.setup-and-validate.outputs.environment }}
        path: ./pipeline-output/
        
    - name: Validate pipeline outputs
      run: |
        cd ./pipeline-output
        
        # Copy validation helper and run it
        cp ../demo-4/pipeline-helpers/pipeline_validator.py .
        python pipeline_validator.py

  deployment-readiness:
    name: Check Deployment Readiness
    runs-on: ubuntu-latest
    needs: [setup-and-validate, run-end-to-end-pipeline, validate-pipeline-output]
    if: needs.run-end-to-end-pipeline.outputs.deployment-ready == 'true'
    environment: ${{ needs.setup-and-validate.outputs.environment }}
    
    steps:
    - name: Download pipeline artifacts
      uses: actions/download-artifact@v4
      with:
        name: pipeline-artifacts-${{ needs.setup-and-validate.outputs.environment }}
        path: ./pipeline-output/
        
    - name: Prepare deployment package
      run: |
        cd ./pipeline-output
        
        echo "📦 Preparing deployment package..."
        
        # Create deployment manifest
        cat > deployment_manifest.json << EOF
        {
          "pipeline_id": "${{ needs.setup-and-validate.outputs.pipeline-id }}",
          "environment": "${{ needs.setup-and-validate.outputs.environment }}",
          "deployment_timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "model_accuracy": ${{ needs.run-end-to-end-pipeline.outputs.best-model-accuracy }},
          "github_sha": "${{ github.sha }}",
          "github_actor": "${{ github.actor }}",
          "artifacts": {
            "model_package": "pipeline_artifacts/deployment_package/",
            "metadata": "cicd_pipeline_summary.json",
            "inference_script": "pipeline_artifacts/deployment_package/inference.py"
          }
        }
        EOF
        
        echo "✅ Deployment package ready"
        cat deployment_manifest.json
        
    - name: Upload deployment package
      uses: actions/upload-artifact@v4
      with:
        name: deployment-package-${{ needs.setup-and-validate.outputs.environment }}
        path: |
          ./pipeline-output/deployment_manifest.json
          ./pipeline-output/pipeline_artifacts/deployment_package/
        retention-days: 90

  pipeline-summary:
    name: Create Pipeline Summary
    runs-on: ubuntu-latest
    needs: [setup-and-validate, run-end-to-end-pipeline, validate-pipeline-output, deployment-readiness]
    if: always()
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Download pipeline artifacts
      uses: actions/download-artifact@v4
      if: needs.run-end-to-end-pipeline.result == 'success'
      with:
        name: pipeline-artifacts-${{ needs.setup-and-validate.outputs.environment }}
        path: ./pipeline-output/
        
    - name: Create comprehensive summary
      run: |
        echo "# 🚀 MLflow End-to-End Pipeline Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Pipeline ID:** ${{ needs.setup-and-validate.outputs.pipeline-id }}" >> $GITHUB_STEP_SUMMARY
        echo "**Environment:** ${{ needs.setup-and-validate.outputs.environment }}" >> $GITHUB_STEP_SUMMARY
        echo "**Triggered by:** ${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
        echo "**Git SHA:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        echo "## 📊 Pipeline Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Stage | Status | Details |" >> $GITHUB_STEP_SUMMARY
        echo "|-------|--------|---------|" >> $GITHUB_STEP_SUMMARY
        echo "| Setup & Validation | ✅ ${{ needs.setup-and-validate.result }} | Environment detection and validation |" >> $GITHUB_STEP_SUMMARY
        echo "| Pipeline Execution | ${{ needs.run-end-to-end-pipeline.result == 'success' && '✅' || needs.run-end-to-end-pipeline.result == 'skipped' && '⏭️' || '❌' }} ${{ needs.run-end-to-end-pipeline.result }} | Complete ML pipeline execution |" >> $GITHUB_STEP_SUMMARY
        echo "| Output Validation | ${{ needs.validate-pipeline-output.result == 'success' && '✅' || needs.validate-pipeline-output.result == 'skipped' && '⏭️' || '❌' }} ${{ needs.validate-pipeline-output.result }} | Validate pipeline artifacts |" >> $GITHUB_STEP_SUMMARY
        echo "| Deployment Readiness | ${{ needs.deployment-readiness.result == 'success' && '✅' || needs.deployment-readiness.result == 'skipped' && '⏭️' || '❌' }} ${{ needs.deployment-readiness.result }} | Prepare deployment package |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ "${{ needs.run-end-to-end-pipeline.result }}" = "success" ]; then
          echo "## 🏆 Pipeline Metrics" >> $GITHUB_STEP_SUMMARY
          echo "- **Best Model Accuracy:** ${{ needs.run-end-to-end-pipeline.outputs.best-model-accuracy }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Deployment Ready:** ${{ needs.run-end-to-end-pipeline.outputs.deployment-ready }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Pipeline Status:** ${{ needs.run-end-to-end-pipeline.outputs.pipeline-status }}" >> $GITHUB_STEP_SUMMARY
        else
          echo "## ⚠️ Pipeline Issues" >> $GITHUB_STEP_SUMMARY
          echo "Pipeline execution failed or was skipped. Check job logs for details." >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## 🔍 Next Steps" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "1. **Check MLflow UI** - Review experiment: \`end_to_end_pipeline_${{ needs.setup-and-validate.outputs.environment }}\`" >> $GITHUB_STEP_SUMMARY
        echo "2. **Download Artifacts** - Pipeline artifacts and deployment packages available" >> $GITHUB_STEP_SUMMARY
        echo "3. **Review Models** - Check registered models and their performance" >> $GITHUB_STEP_SUMMARY
        
        if [ "${{ needs.run-end-to-end-pipeline.outputs.deployment-ready }}" = "true" ]; then
          echo "4. **Deploy Model** - Deployment package ready for SageMaker deployment (requires approval)" >> $GITHUB_STEP_SUMMARY
        else
          echo "4. **Investigate Issues** - Model not ready for deployment, review quality gates" >> $GITHUB_STEP_SUMMARY
        fi
        
    - name: Generate HTML Reports
      if: needs.run-end-to-end-pipeline.result == 'success'
      run: |
        cd ./pipeline-output
        
        # Copy HTML report generator
        cp ../demo-4/pipeline-helpers/html_report_generator.py .
        
        # Generate HTML reports
        python html_report_generator.py
        
        echo "📊 HTML reports generated for leadership team" >> $GITHUB_STEP_SUMMARY
        echo "- Executive Summary: executive_summary.html" >> $GITHUB_STEP_SUMMARY
        echo "- Technical Report: technical_report.html" >> $GITHUB_STEP_SUMMARY
        
    - name: Upload HTML Reports
      uses: actions/upload-artifact@v4
      if: needs.run-end-to-end-pipeline.result == 'success'
      with:
        name: html-reports-${{ needs.setup-and-validate.outputs.environment }}
        path: |
          ./pipeline-output/executive_summary.html
          ./pipeline-output/technical_report.html
        retention-days: 90

  sagemaker-deployment-approval:
    name: Approve SageMaker Deployment
    runs-on: ubuntu-latest
    needs: [setup-and-validate, run-end-to-end-pipeline, deployment-readiness, pipeline-summary]
    if: |
      always() && 
      needs.run-end-to-end-pipeline.result == 'success' && 
      needs.run-end-to-end-pipeline.outputs.deployment-ready == 'true' && 
      needs.setup-and-validate.outputs.environment == 'production'
    environment: 
      name: sagemaker-production
      url: https://console.aws.amazon.com/sagemaker/
    
    steps:
    - name: Request deployment approval
      run: |
        echo "## 🚨 SageMaker Deployment Approval Required" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Model Details:**" >> $GITHUB_STEP_SUMMARY
        echo "- **Pipeline ID**: ${{ needs.setup-and-validate.outputs.pipeline-id }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Environment**: ${{ needs.setup-and-validate.outputs.environment }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Model Accuracy**: ${{ needs.run-end-to-end-pipeline.outputs.best-model-accuracy }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Deployment Status**: ${{ needs.run-end-to-end-pipeline.outputs.deployment-ready }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Git SHA**: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Triggered by**: ${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**⚠️ This deployment will:**" >> $GITHUB_STEP_SUMMARY
        echo "- Deploy the model to AWS SageMaker" >> $GITHUB_STEP_SUMMARY
        echo "- Create a SageMaker endpoint for -time inference" >> $GITHUB_STEP_SUMMARY
        echo "- Replace any existing production model" >> $GITHUB_STEP_SUMMARY
        echo "- Incur AWS costs for the endpoint" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**✅ Approval granted by**: ${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
        echo "**📅 Approval time**: $(date -u +%Y-%m-%dT%H:%M:%SZ)" >> $GITHUB_STEP_SUMMARY

  deploy-to-sagemaker:
    name: Deploy to SageMaker
    runs-on: ubuntu-latest
    needs: [setup-and-validate, run-end-to-end-pipeline, deployment-readiness, sagemaker-deployment-approval]
    if: needs.sagemaker-deployment-approval.result == 'success'
    environment: sagemaker-production
    timeout-minutes: 30
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ vars.AWS_REGION || 'us-east-1' }}
        
    - name: Download deployment artifacts
      uses: actions/download-artifact@v4
      with:
        name: deployment-package-${{ needs.setup-and-validate.outputs.environment }}
        path: ./deployment-package/
        
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Install SageMaker dependencies
      run: |
        pip install boto3 sagemaker scikit-learn==1.3.2 mlflow==2.12.1 joblib
        
    - name: Copy SageMaker deployment script
      run: |
        cp demo-4/pipeline-helpers/sagemaker_deployer.py .
        
    - name: Deploy to SageMaker
      env:
        SAGEMAKER_ROLE: ${{ secrets.SAGEMAKER_EXECUTION_ROLE }}
      run: |
        python sagemaker_deployer.py
        
    - name: Upload SageMaker deployment info
      uses: actions/upload-artifact@v4
      with:
        name: sagemaker-deployment-info
        path: sagemaker_deployment_info.json
        retention-days: 30
        
    - name: Generate deployment HTML reports
      run: |
        # Download pipeline artifacts for report generation
        mkdir -p ./pipeline-output
        
        # Copy HTML report generator
        cp demo-4/pipeline-helpers/html_report_generator.py ./pipeline-output/
        
        # Copy deployment artifacts
        cp sagemaker_deployment_info.json ./pipeline-output/
        
        # We need the pipeline summary too - create a minimal one if it doesn't exist
        if [ ! -f "./pipeline-output/cicd_pipeline_summary.json" ]; then
          cat > ./pipeline-output/cicd_pipeline_summary.json << EOF
        {
          "pipeline_name": "${{ needs.setup-and-validate.outputs.pipeline-id }}",
          "environment": "${{ needs.setup-and-validate.outputs.environment }}",
          "pipeline_status": "completed",
          "best_accuracy": ${{ needs.run-end-to-end-pipeline.outputs.best-model-accuracy }},
          "deployment_ready": true,
          "quality_gate_passed": true,
          "github_sha": "${{ github.sha }}",
          "github_actor": "${{ github.actor }}"
        }
        EOF
        fi
        
        cd ./pipeline-output
        python html_report_generator.py
        
        echo "📊 Deployment HTML reports generated" >> $GITHUB_STEP_SUMMARY
        echo "- Executive Summary with deployment details: executive_summary.html" >> $GITHUB_STEP_SUMMARY
        echo "- Technical Report with deployment info: technical_report.html" >> $GITHUB_STEP_SUMMARY
        
    - name: Upload deployment HTML reports
      uses: actions/upload-artifact@v4
      with:
        name: deployment-html-reports
        path: |
          ./pipeline-output/executive_summary.html
          ./pipeline-output/technical_report.html
        retention-days: 90
        
    - name: Create deployment summary
      run: |
        echo "## 🎉 SageMaker Deployment Successful" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "sagemaker_deployment_info.json" ]; then
          ENDPOINT_NAME=$(python -c "import json; print(json.load(open('sagemaker_deployment_info.json'))['endpoint_name'])")
          MODEL_NAME=$(python -c "import json; print(json.load(open('sagemaker_deployment_info.json'))['model_name'])")
          
          echo "**Deployment Details:**" >> $GITHUB_STEP_SUMMARY
          echo "- **Endpoint Name**: \`$ENDPOINT_NAME\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Model Name**: \`$MODEL_NAME\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Region**: ${{ vars.AWS_REGION || 'us-east-1' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Instance Type**: ml.t2.medium" >> $GITHUB_STEP_SUMMARY
          echo "- **Deployment Time**: $(date -u +%Y-%m-%dT%H:%M:%SZ)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**🔗 Useful Links:**" >> $GITHUB_STEP_SUMMARY
          echo "- [SageMaker Console](https://console.aws.amazon.com/sagemaker/)" >> $GITHUB_STEP_SUMMARY
          echo "- [CloudWatch Logs](https://console.aws.amazon.com/cloudwatch/home#logsV2:log-groups)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**📝 Usage Example:**" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`python" >> $GITHUB_STEP_SUMMARY
          echo "import boto3" >> $GITHUB_STEP_SUMMARY
          echo "import json" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "client = boto3.client('sagemaker-runtime')" >> $GITHUB_STEP_SUMMARY
          echo "response = client.invoke_endpoint(" >> $GITHUB_STEP_SUMMARY
          echo "    EndpointName='$ENDPOINT_NAME'," >> $GITHUB_STEP_SUMMARY
          echo "    ContentType='application/json'," >> $GITHUB_STEP_SUMMARY
          echo "    Body=json.dumps({" >> $GITHUB_STEP_SUMMARY
          echo "        'instances': [[50000, 700, 120000, 5, 0.35, 8, 1, 1, 0]]" >> $GITHUB_STEP_SUMMARY
          echo "    })" >> $GITHUB_STEP_SUMMARY
          echo ")" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
        fi